---
title: K-Means Cluster Analysis of Milwaukee K12 Schools
author: Spencer Schien
date: '2020-01-27'
slug: cluster-analysis-of-milwaukee-k12-schools
categories:
  - Machine Learning
tags:
  - R
  - Cluster Analysis
  - k-means
subtitle: ''
summary: ''
authors: []
lastmod: '2020-01-27T13:13:49-06:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
reading_time: false
share: false
draft: false
commentable: true
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(
  warning = FALSE, 
  message = FALSE
  ) 
```
# Introduction

Let's say you're doing an analysis of K12 schools, and you want to group schools based on the student populations they serve.  One way to accomplish this task is to use the *k-means clustering algorithm* to group schools into a perdefined (i.e. *k*) number of groups or clusters.

*k*-means clustering will group the schools in *k* groups so that each school is in the group for which it is closes to the group average.  

# Cluster Analysis

## Importing the Data

For this post, I will be using data made publicly available through the Wisconsin School Report Cards.  I have pre-processed this data in into an R package called *wisconsink12*, and it can be downloaded from GitHub with the following code:

```{r eval=FALSE}
# Use devtools to install from GitHub

devtools::install_github("cityforwardcollective/wisconsink12")
```

More information on accessing data in this package can be found on the package's [GitHub repo](https://github.com/cityforwardcollective/wisconsink12) -- here I will only provide instructions pertaining to the analysis at hand.

Once the package is loaded, we have access to several tables and functions to process those tables into commonly-needed formats.  The code below will prepare a dataframe suitable for our purposes.

```{r}
library(tidyverse)  # I'll use this package for data processing
library(wisconsink12)

# Create the dataframe with a wisconsink12 function

make_mke_rc()

# Process dataframe for student demographic data

demo_rc <- mke_rc %>%
  select(school_year,
         dpi_true_id,  # School unique identifier
         starts_with("per"),  # Select student demographic variables
         -c(per_choice, per_open)) %>% # Drop % Choice and % Open Enrollment
  filter(school_year == "2018-19")

```

We now have a dataframe `demo_rc` that contains variables for the school year, a unique identifier for the school, and the race/ethnicity, economic status, disability status, and English proficiency status of the student body.  All of the student-descriptive variables are represented as proportions of the whole, the same as a percentage divided by 100.  We will be grouping the schools based on these variables.

## Preparing the Data

Now that we have our data loaded, we can turn towards the actual process of implementing the *k*-means algorithm.  Our first step is to ensure that our data is scaled appropriately.

Simply stated, the *k*-means algorithm will calculate the distance of an observation's variable from a cluster center.  In terms of this analysis, an observation would be a school, and a variable would be any of those student body charactistics, such as percent of economically disadvantaged students.  All of these variables are ratios of one, but if the variance and spread of the variables is not the same, then a variable with the most variance will have more influence than a variable with little variance.  To mitigate this effect, we will first scale the data.

```{r}
# scale() will scale our data

scaled_demo <- scale(demo_rc[3:10])
```

Now that the data is scaled, we can perform the first step in clustering, which is calculating a distance object that will be used by the clustering algorithm.

```{r}
# dist() wills calculate dist object

dist_demo <- dist(scaled_demo)
```

With our `dist` object now calculated, we are prepared to run the algorithm.  Implementation of the algorithm itself is fairly straightforward -- basically, you need to identify x (for us that is the `dist` object), and the number of centers.  This can be coded as `kmeans(dist_demo, 3)`.  

What we've omitted so far is any analysis to aid us in choosing *k*, the number of clusters.  As it turns out, this will be our most difficult task.  

## Determining *k*

Two popular methods for determining the number of clusters to choose (when unkown, as in our case) are the *Elbow Method* and the *Average Silhouette Method*.  

## Elbow Method

The elbow method is based on the total within-cluster sum of squares (WSS). Total WSS is a measure of variance within each cluster -- put another way, it's a measure of the distance between the actual observations in each cluster and the cluster center.  With the elbow method, we are looking to minimize the total WSS, meaning observations are as close to group averages as possible.

The `kmeans()` function will actually provide the total WSS as an output, so we can employ some functional programming to evaluate *k* values between one and ten.

```{r}
# Elbow Analysis

tot_withinss <- map_dbl(1:10, function(k) {
  model = kmeans(x = dist_demo, centers = k)
  model$tot.withinss
})

elbow_df <- data.frame(
  k = 1:10,
  tot_withinss = tot_withinss
)

elbow_df %>%
  ggplot(aes(k, tot_withinss)) +
  geom_line() +
  scale_x_continuous(breaks = 2:10) +
  labs(title = "Elbow Method: Total Within-Cluster Sum of Square")


# Silhouette Analysis
library(cluster)

sil_width <- map_dbl(2:10, function(k){
  model <- pam(x = dist_demo, k = k)
  model$silinfo$avg.width
})
sil_df <- data.frame(
  k = 2:10,
  sil_width = sil_width
)

sil_df %>%
  ggplot(aes(k, sil_width)) +
  geom_line() +
  scale_x_continuous(breaks = 2:10) +
  labs(title = "Average Silhouette Method")

# Final Clustering with 3 Clusters

k_clust <- kmeans(dist_demo, centers = 3)

ach_clustered <- mke_rc %>%
  filter(school_year == "2018-19") %>%
  mutate(cluster = as_factor(k_clust$cluster))

n_demo <- ach_clustered %>%
  group_by(cluster) %>%
  summarise(N = n())

c_demo <- ach_clustered %>%
  group_by(cluster) %>%
  summarise_at(vars(per_am_in:per_lep, overall_score, sch_ach, sch_growth), .funs = mean, na.rm = TRUE) %>%
  modify_at(vars(per_am_in:per_lep), scales::percent)
```
